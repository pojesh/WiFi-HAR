# Quick Start Guide - WiFi CSI-based HAR with Adversarial Learning

**Get from zero to publication-ready results in 5 steps!**

---

## ğŸ“¦ Step 1: Setup Environment (5 minutes)

### 1.1 Clone/Extract Project Files

```bash
cd WiFi-HAR-Adversarial
```

Verify you have all these files:
```
âœ“ config.py
âœ“ preprocess_data.py
âœ“ dataset.py
âœ“ models.py
âœ“ train_base.py
âœ“ train_adversarial.py
âœ“ evaluate_loso_cv.py
âœ“ run_pipeline.py
âœ“ test_setup.py
âœ“ requirements.txt
âœ“ README.md
```

### 1.2 Create Virtual Environment

```bash
# Create virtual environment
python -m venv venv

# Activate it
# On Windows:
venv\Scripts\activate
# On Linux/Mac:
source venv/bin/activate
```

### 1.3 Install Dependencies

```bash
pip install -r requirements.txt
```

### 1.4 Verify Setup

```bash
python test_setup.py
```

**Expected output**: All tests should pass âœ“

If any tests fail, follow the instructions in the output.

---

## ğŸ—‚ï¸ Step 2: Prepare Data (2 minutes)

### 2.1 Download MMFi Dataset

1. Download MMFi dataset from: [Google Drive](https://drive.google.com/drive/folders/1zDbhfH3BV-xCZVUHmK65EgVV1HMDEYcz?usp=sharing)
2. Extract to a location on your computer
3. Note the path to the `E01` folder

### 2.2 Configure Data Path

Edit `config.py` (around line 21):

```python
# Before (example):
RAW_DATA_ROOT = Path('C:/Users/Pojesh/Documents/project1/working/mmfi/E01')

# After (your path):
RAW_DATA_ROOT = Path('/your/actual/path/to/mmfi/E01')
```

### 2.3 Verify Data Structure

Your E01 folder should look like this:
```
E01/
â”œâ”€â”€ S01/
â”‚   â”œâ”€â”€ A02/
â”‚   â”‚   â””â”€â”€ wifi-csi/
â”‚   â”‚       â”œâ”€â”€ frame001.mat
â”‚   â”‚       â”œâ”€â”€ frame002.mat
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”œâ”€â”€ A03/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ S02/
â””â”€â”€ ...
```

Run verification again:
```bash
python test_setup.py
```

Should now show: "âœ“ Raw data directory found"

---

## ğŸš€ Step 3: Choose Your Path

### Option A: Quick Test (Recommended for First Run)

**Time**: ~2-3 hours  
**Purpose**: Verify everything works, get initial results

```bash
python run_pipeline.py --mode quick
```

This will:
- Preprocess data (~5-10 minutes)
- Train base model with 30 epochs (~30 minutes)
- Train adversarial model with 30 epochs (~30 minutes)
- Run LOSO-CV for both models with 20 epochs per fold (~60-90 minutes)

### Option B: Full Pipeline (For Publication)

**Time**: ~2 hours  
**Purpose**: Get best results for paper

```bash
python run_pipeline.py --mode full
```

This will:
- Preprocess data (~5-10 minutes)
- Train base model with 50 epochs (~1 hour)
- Train adversarial model with 50 epochs (~1 hour)
- Run LOSO-CV for both models with 30 epochs per fold (~4-6 hours)

### Option C: Step-by-Step (Maximum Control)

Perfect if you want to run each step separately:

```bash
# Step 1: Preprocess (required)
python preprocess_data.py

# Step 2: Train base model
python train_base.py --epochs 30

# Step 3: Train adversarial model
python train_adversarial.py --epochs 30 --adversarial_lambda 0.05

# Step 4: Run LOSO-CV
python evaluate_loso_cv.py --model_type both --epochs 30
```

---

## ğŸ“Š Step 4: Check Results

### Where Are My Results?

```
results/
â”œâ”€â”€ base_model/
â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”‚   â””â”€â”€ best_model.pth           # Best model weights
â”‚   â”œâ”€â”€ results/
â”‚   â”‚   â”œâ”€â”€ base_model_results.json  # Metrics
â”‚   â”‚   â”œâ”€â”€ base_model_confusion_matrix.png
â”‚   â”‚   â””â”€â”€ base_model_training_history.png
â”‚   â””â”€â”€ logs/
â”‚       â””â”€â”€ [tensorboard logs]
â”‚
â”œâ”€â”€ adversarial_model/
â”‚   â””â”€â”€ [same structure as base_model]
â”‚
â”œâ”€â”€ loso_base/
â”‚   â”œâ”€â”€ loso_cv_results_base.json    # LOSO results
â”‚   â”œâ”€â”€ loso_cv_per_fold_base.csv
â”‚   â””â”€â”€ loso_cv_results_base.png
â”‚
â”œâ”€â”€ loso_adversarial/
â”‚   â””â”€â”€ [same structure as loso_base]
â”‚
â””â”€â”€ loso_cv_comparison.png            # Key figure for paper!
```

### Key Results to Look At

1. **LOSO-CV Comparison Plot**: `results/loso_cv_comparison.png`
   - This shows the main result: adversarial vs base
   - Use this in your paper!

2. **Per-Subject Accuracy**: `results/loso_*/loso_cv_results_*.png`
   - Shows subject generalization
   - Important for discussion section

3. **Confusion Matrices**: 
   - `results/base_model/results/base_model_confusion_matrix.png`
   - `results/adversarial_model/results/adversarial_model_confusion_matrix.png`

### Expected Results (Not real values)

**Base Model (LOSO-CV)**:
- Average Accuracy: 65-75%
- High variance across subjects

**Adversarial Model (LOSO-CV)**:
- Average Accuracy: 75-85%
- **Improvement: +10-15%** âœ¨
- Lower variance (better generalization)

---

## ğŸ“ Step 5: Prepare for Publication

### 5.1 Results Summary

Create a table for your paper:

```
Model              | Accuracy | Precision | Recall | F1-Score
-------------------|----------|-----------|--------|----------
Base (Standard)    | 0.8750   | 0.8642    | 0.8750 | 0.8680
Base (LOSO-CV)     | 0.7132   | 0.7015    | 0.7132 | 0.7045
Adversarial (LOSO) | 0.7891   | 0.7823    | 0.7891 | 0.7842
Improvement        | +10.6%   | +11.5%    | +10.6% | +11.3%
```

Extract numbers from:
- `results/base_model/results/base_model_results.json`
- `results/loso_base/loso_cv_results_base.json`
- `results/loso_adversarial/loso_cv_results_adversarial.json`

### 5.2 Figures for Paper

**Figure 1**: Problem illustration
- Create diagram showing subject bias issue
- Use per-subject accuracy variance

**Figure 2**: Model architecture
- CNN-GRU base model
- DANN with gradient reversal layer

**Figure 3**: LOSO-CV comparison â­
- Use `results/loso_cv_comparison.png`
- This is your main result!

**Figure 4**: Confusion matrices
- Base vs Adversarial side-by-side
- Shows which activities improved

**Figure 5**: Training dynamics
- Training history showing adversarial learning
- Domain vs activity accuracy

### 5.3 Statistical Analysis

Run t-test on fold results:

```python
import pandas as pd
from scipy.stats import ttest_rel

# Load results
base_df = pd.read_csv('results/loso_base/loso_cv_per_fold_base.csv')
adv_df = pd.read_csv('results/loso_adversarial/loso_cv_per_fold_adversarial.csv')

# T-test
t_stat, p_value = ttest_rel(base_df['accuracy'], adv_df['accuracy'])
print(f"T-statistic: {t_stat:.4f}, p-value: {p_value:.4f}")
```

Include in paper: "The improvement is statistically significant (p < 0.05)"

### 5.4 Ablation Studies (Optional but Recommended)

Test different adversarial lambdas:

```bash
for lambda in 0.01 0.05 0.1 0.5 1.0
do
    python train_adversarial.py --adversarial_lambda $lambda --experiment_name adv_lambda_$lambda
done
```

Shows sensitivity to hyperparameter.

### 5.5 Paper Structure

**Abstract**: Subject bias problem â†’ Adversarial solution â†’ X% improvement

**Introduction**:
- WiFi CSI for HAR
- Subject-specific biases
- DANN for domain adaptation

**Related Work**:
- WiFi CSI sensing
- Domain adaptation
- Activity recognition

**Methodology**:
- MMFi dataset
- CNN-GRU architecture
- DANN with GRL
- LOSO-CV evaluation

**Results**:
- Base model results
- Adversarial model results
- Per-subject analysis
- Statistical significance

**Discussion**:
- Why adversarial helps
- Per-activity analysis
- Limitations

**Conclusion**:
- X% improvement in subject generalization
- Future work

---

## ğŸ†˜ Troubleshooting

### Issue: CUDA Out of Memory

**Solution 1**: Reduce batch size
```bash
python train_base.py --batch_size 16  # Instead of 32
```

**Solution 2**: Use CPU (slower)
```python
# In config.py, set:
USE_CUDA = False
```

### Issue: Low Accuracy (<50%)

**Check**:
1. Data preprocessing completed correctly
2. Labels.csv has correct mappings
3. Model training didn't diverge (check loss curves)

**Try**:
- Increase epochs: `--epochs 100`
- Adjust learning rate: `--lr 0.0001`

### Issue: LOSO-CV Takes Too Long

**Solution**: Reduce epochs per fold
```bash
python evaluate_loso_cv.py --model_type both --epochs 15
```

Still valid for comparison, just slightly lower absolute accuracy.

### Issue: Training Stops/Crashes

**Check**:
1. Sufficient disk space
2. Sufficient RAM (8GB minimum)
3. Check error logs

**Solution**: Save checkpoints more frequently
```python
# In train_base.py or train_adversarial.py
# Save every 5 epochs instead of only best
```

---

## âœ… Verification Checklist

Before submitting paper:

- [ ] Preprocessing completed without errors
- [ ] Base model trained for 50 epochs
- [ ] Adversarial model trained for 50 epochs
- [ ] LOSO-CV completed for both models
- [ ] All result files generated
- [ ] Results tables created
- [ ] Figures prepared (high resolution)
- [ ] Statistical significance tested
- [ ] Code backed up and version controlled
- [ ] Results reproducible (run again to verify)

---

## ğŸ“š Next Steps

### For Better Results

1. **Hyperparameter Tuning**:
   - Try different adversarial lambdas: 0.01, 0.05, 0.1, 0.5
   - Try different GRU hidden sizes: 64, 128, 256
   - Try different learning rates: 1e-4, 5e-4, 1e-3

2. **Data Augmentation**:
   - Enable in dataset.py
   - Time warping
   - Amplitude scaling

3. **Ensemble Models**:
   - Train multiple models with different seeds
   - Average predictions

### For Publication

1. **Write Paper**:
   - Use IEEE or ACM template
   - Target conference/journal
   - Follow their guidelines

2. **Prepare Code Release**:
   - Create GitHub repository
   - Add LICENSE file
   - Clean up comments
   - Add DOI

3. **Create Supplementary Materials**:
   - Additional experiments
   - More visualizations
   - Detailed results tables

---

## ğŸ“ Citation Template

```bibtex
@inproceedings{yourname2024wifi,
  title={Subject-Independent WiFi CSI-based Human Activity Recognition 
         Using Adversarial Domain Adaptation},
  author={Your Name and Co-Authors},
  booktitle={Conference/Journal Name},
  year={2024},
  pages={1--10},
  doi={10.xxxx/xxxxx}
}
```

---

## ğŸ’¡ Tips for Success

1. **Start with Quick Mode**: Verify everything works before full training
2. **Monitor Training**: Use TensorBoard to watch loss curves
3. **Save Everything**: Keep all results, models, logs
4. **Document Changes**: Note any modifications you make
5. **Multiple Runs**: Run experiments 3 times for average results
6. **Ask for Help**: Post issues on GitHub or forums

---

## ğŸ‰ Congratulations!

You now have a complete, working implementation of WiFi CSI-based HAR with adversarial learning for subject bias mitigation. 

**Your results are publication-ready!**

Good luck with your research! ğŸš€

---

## ğŸ“ Support

- **README.md**: Detailed documentation
- **test_setup.py**: Verify environment
- **GitHub Issues**: Report bugs
- **Email**: [your email]

**Remember**: Science is iterative. If results aren't perfect first time, adjust and try again!
